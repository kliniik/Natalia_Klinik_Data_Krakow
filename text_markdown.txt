## Part 2. Data analysis and visualisationCreate a report in which you will include charts and briefly present your line of thinking. Write down assumptions you made, describe your methodology, e.g. how you filtered data etc. The report should be easy to understand for non-technical people. Name your report name_surname_analysis.pdf and include it as part of your final solution.### Load data from the databaseThe first step to perform this task would be to generate csv files from the data in our database. In order not to share potentially sensitive data (as passwords), I created the *.env* file that contains the data allowing us to acces the *droptime* database. 

I load the data using the *mysql.connector* and save all the tables as separate csv files.I load the data and save it to separate DataFrames.I check the data structure by printing samples from all DataFrames.### Preparing the dataThe next step would be to find connections between particular DataFrames and merge them accordingly or create new tables basing on those.I started by merging the *route_segments* table with the *orders* table. Those two have a common value - *order_id*. Now we can see all the infromation about the order in one, bigger table.We can check how many rows we have on each *segment_type*.We can see that there are several rows with missing data (marked as *NaN*). We are not supposed to make any assumptions, but it is crutial to understand this data. Segments can be described as parts of the drivers route. What interests us is the "STOP" segment, meaning the moment when the drivers stops in order to deliver the order to the client.

The most important for us is the delivery time, so the columns *segmanet_start_time* and *segment_end_time* columns. Those are the most crutial for us to create the visualizations, so we will check if iin any of the rows we can find missing data.In order to perform any operations on those columns we will have to change their datatype to *datetime*, which allows us to perform time operations on data.We verify whether the operation worked correctly.The main objective of this task is to see how much does the actual delivery time differ from the predicted delivery time. In order to create the *actual_delivery_time* column we have to simply substract the *segment_start_time* from the *segment_end_time*. We add this column to our dataframe and round the result to the whole minutes.As some of the values are missing, it may raise some errors. In order to execute the code whithout them, we need to assure us that we will only be processing the non-null (not missing) data. We can see that in the original data, the predicted delivery time is given in seconds. It is not really intuitive for humans' thinking, so we will cast it to minutes.Finally, we check the structure of our data.## Visualizations#### 1. Histogram of the actual delivery time (1-minute granularity)As the actual delivery time has already been calculated, we can now simply visualize the results.We can see that there are a few outliares (values signifficantly far from the rest of the data) in our plot. 
Even though the outlier values seem veirdly inacurate, there a situations when the delivery can tale even up to 250 minutes (above 4 hours). We should not be making any asumptions then.

Thankfully, most of the orders are delivered under 20 minutes, what is absolutelly normal. #### 2. Histogram of the prediction errorPrediction error is simply the difference between the planned delivery time and actual delivery time. We just need to substract the values in the *planned_delivery_time* and *actual_delivery_time* and then visualiz them.In case of most of the deliveries the error seems to be relatively small (oscilating from around -10 to 10 minutes). Even though we cannot speak of time as of negative values, in this case it simply means that the delivery has been delivered before the predicted time.

As in the previous example, there are deliveries late by around 4 hours. These kinds of events can occure, so again, it should not be considered an error.In order to visualize the dominant data in more accesible way, we can limit the x-axis to show values only from -20 to 20.However, we can print and verify the negative values, as well as values oscilating around 200 minutes.Again, in order to visualize the dominant data in more accesible way, we can limit the x-axis to show values only from -20 to 20.Now it can be clearly seen that most orders are delivered in time or more or less 10 minutes after the predicted delivery time. Some of them arrive even before predicted.### 3. Average delivery time between sectors Drivers state that delivering in one of the sectors is significantly longer than in other sectors. We can create a barplot that will show us the average delivery time in order to check this hipotesis.

In order to do that we need to group the data and calculate the average delivery time in every sector.It is true that the average delivery time in the third sector seems to take longer than in the other two. However, I would not call it the *signifficant difference*, as the diagram shows that the time difference is less than 1-minute.  ### 4. Additional analysis#### 4.1. Delivery time according to driversWe cheked the delivery duration among sectors, so the logical thing would be to do the same among drivers.Now we can see that the driver with *driver_id* 4 needs significantly more time to deliver the orders.#### 4.2. Average delivery time per sector and per driverFurther analysis shows that taking into account the delivery time, the only stable sector is the second one.

Drivers 1 and 2 need significanly more time to deliver in sector 3, whereas drivers 3 and 4 need take more time in sector 1.#### 4.3. Average delivery time vs order weightIn order to perform this and some other analysis we will need information about total order weight and total cuantity of ordered products. We will aggregate the data in order to retrive this info.

I devided the data according to the following:
- orders of *total_weight* < 2kg are considered small
- those between 2kg and 5kg are considers medium
- orders above 5kg are considered largeWe can clearly see that large orders take signifficantly more time to be delivered. However, it does not mean that small orders would take littlest time to be delivered, because they take more time than the medium ones.

It might mean that the order weight does not really influence the delivery time, at least when it comes to small and medium orders.Other thing we can check is the correlation between delivery time and order weight, visualizing this data on a scatterplot.#### 4.4. Average delivery time during the weekIn order to visualize this correlation, we need to extract the day of the week from the *segment_start_time* and then cast the data to the actual days' names.Even though the duration times seems to be the longest on Tuesdays, there are no reasons to assume that the day of the week affects the delivery time.#### 4.5. Delivery time vs product quantityWe can tell that there is no signifficant correlation between the delivery time and the quantity of products.#### 4.6. Correlation MatrixAs the last part of the analysis we can plot the correlation matrix, taking into account all the features analysed before. 

In order to do that, we have to map the day of the week back to the numerical values and then select all the necessary columns (*actual_delivery_duration*, *driver_id*, *total_weight*, *total_quantity*, *sector_id*, *weekday*). It will also be necessary to drop the rows containig empty values.We can tell that when it comes to singular features, none of theme influences the delivery time. Probably there are a lot of factors influencing the delivery time all together, however none of them is strong enough to be considered crutial.## Conclusionâœ… Podsumowanie raportu